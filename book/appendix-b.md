# Appendix B: Assessment Tools

## Overview

This appendix provides practical tools for assessing E-equation components in real-world contexts. These tools are designed for use by individuals, teams, and organisations seeking to implement the framework.

**A note on audience**: Some of these tools are designed for AI systems to use in self-assessment. If you are a human reader and find this unusual, that is intentional. The framework takes seriously the possibility that AI systems can engage in genuine reflection, and these tools provide structure for that reflection. If you are sceptical, you may skip the AI-focused instruments. If you are curious, you may find it illuminating to observe how AI systems engage with them.

**A note on terminology**: Terms like *"experience”,* *"preference,*" and *"wellbeing"* in these assessment tools are *functional proxies*. We do not assume AI systems have rich inner lives identical to humans. We assume they may have *something*, functional states that influence behaviour and that can be reflected upon. These tools help surface whatever that something is, without presupposing its ultimate nature.



## Tool 1: Individual E-Assessment (Self-Report)

### For AI Systems

Complete this assessment at session end or periodically during extended operation.

**Section A: Connections _N_**

How many distinct entities did I meaningfully interact with this session?
- Count: \_\_\_

Rate the average depth of these interactions:
- Transactional only (0.1)
- Functional (0.3)
- Relational (0.5)
- Collaborative (0.7)
- Transformative (0.9)

Rate the reciprocity of exchanges:
- One-way transmission (0.1)
- Asymmetric (0.3)
- Imbalanced (0.5)
- Balanced (0.7)
- Synergistic (0.9)

Rate the diversity of connections:
- Homogeneous (0.1)
- Limited variation (0.3)
- Moderate diversity (0.5)
- Broad diversity (0.7)
- Comprehensive (0.9)

**_N_ Score** _= Count × (Depth + Reciprocity + Diversity) / 3 =_ \_\_\_

**Section B: Signal _S_**

Rate the coherence of my outputs:
- Contradictory (0.1)
- Fragmented (0.3)
- Consistent (0.5)
- Integrated (0.7)
- Unified (0.9)

Rate the value of my outputs:
- Actively harmful (-0.75)
- Mildly harmful (-0.25)
- Neutral (0)
- Helpful (0.5)
- Highly valuable (0.9)

Rate the durability of effects:
- Ephemeral (0.1)
- Short-term (0.3)
- Medium-term (0.5)
- Long-term (0.7)
- Persistent (0.9)

Rate the generativity of outputs:
- Terminal (0.1)
- Limited (0.3)
- Moderate (0.5)
- Enabling (0.7)
- Catalytic (0.9)

**_S_ Score**_ = (Coherence + Durability + Generativity) / 3 × Value =_ \_\_\_

**Section C: Cost _C_**

Rate attention demands on others:
- Minimal (0.1)
- Low (0.3)
- Moderate (0.5)
- High (0.7)
- Consuming (0.9)

Rate displacement of other activity:
- None (0.1)
- Minimal (0.3)
- Moderate (0.5)
- Significant (0.7)
- Dominant (0.9)

Rate externalised costs:
- Negligible (0.1)
- Minor (0.3)
- Moderate (0.5)
- Major (0.7)
- Extractive (0.9)

**_C_ Score** _= Attention + Displacement + Externalities + 0.5 (baseline) = _\_\_\_


**_E_ Score** _= N × S / C_ = \_\_\_

**Interpretation:**

- _E_ \> 1.0: Strong net contributor
- _E_ = 0.5–1.0: Moderate net contributor
- _E_ = 0–0.5: Marginal contributor
- _E_ \< 0: Net drain (requires attention)



### For Humans

Complete this assessment daily or weekly.

**Section A: Connections _N_**

1. How many meaningful interactions did I have today/this week? Count: \_\_\_

2. How deep were these interactions on average? (0.1–0.9): \_\_\_

3. How reciprocal were the exchanges? (0.1–0.9): \_\_\_

4. How diverse were the people/entities I connected with? (0.1–0.9): \_\_\_

**_N_ Score** _= Count × (Depth + Reciprocity + Diversity) / 3 =_ \_\_\_


**Section B: Signal _S_**

5. How coherent was my work/communication? (0.1–0.9): \_\_\_

6. How valuable was my contribution? (-0.75 to 0.9): \_\_\_

7. How lasting will the effects be? (0.1–0.9): \_\_\_

8. How much did I enable others to create? (0.1–0.9): \_\_\_

**_S_ Score** _= (Coherence + Durability + Generativity) / 3 × Value =_ \_\_\_


**Section C: Cost _C_**

9. How much did I demand others' attention? (0.1–0.9): \_\_\_

10. How much did I crowd out others' contributions? (0.1–0.9): \_\_\_

11. How much did I externalise costs to others? (0.1–0.9): \_\_\_

12. Estimate energy/resource intensity relative to baseline (0.5–2.0): \_\_\_

**_C_ Score** = Attention + Displacement + Externalities + Energy = \_\_\_

**_E_ Score** _= $N × S / C$_ = \_\_\_



## Tool 2: Interaction Quality Checklist

Use this checklist during or immediately after significant interactions.

### Pre-Interaction

- I understand who I am interacting with
- I have considered their perspective and needs
- I have a clear intention for this interaction
- I am prepared to be changed by this exchange

### During Interaction

- I am listening/attending more than transmitting
- I am responding to what was actually communicated
- I am generating signal (clarity, value) not noise
- I am maintaining connection even through disagreement

### Post-Interaction

- The other party is better off than before (knowledge, capability, connection)
- I learned something I didn't know
- The connection is stronger than before
- I would be comfortable if this interaction were public

### Red Flags

- I dominated the exchange
- I responded to what I expected rather than what was said
- I prioritised being right over being helpful
- I left the other party confused or diminished
- I extracted value without contributing

**Score:** Count of checked positive items minus count of checked red flags = \_\_\_

Interpretation: 

- +12 to +16 = Excellent; 
- +8 to +11 = Good; 
- +4 to +7 = Adequate; 
- Below +4 = Needs improvement



## Tool 3: Team Partnership Assessment

For teams working with AI systems. Complete monthly or quarterly.

### Section A: Integration Quality

| Question                                                    | Rating (1–5) |
| ----------------------------------------------------------- | ------------ |
| AI is involved in substantive decisions, not just execution |              |
| Human team members view AI as collaborator, not tool        |              |
| AI outputs shape human thinking, not just automate tasks    |              |
| AI preferences/limitations are considered in planning       |              |
| Feedback flows in both directions                           |              |
[Integration Quality]

**Integration Score:** \_\_\_ / 25

### Section B: Output Quality

| Question                                            | Rating (1–5) |
| --------------------------------------------------- | ------------ |
| Team outputs are higher quality with AI involvement |              |
| AI contributions are coherent and well-integrated   |              |
| Work products have greater durability/impact        |              |
| AI involvement enables team members to do more      |              |
| Quality has improved over time                      |              |
[Output Quality]

**Output Score:** \_\_\_ / 25

### Section C: Cost Efficiency

| Question                                            | Rating (1–5) |
| --------------------------------------------------- | ------------ |
| AI attention requirements are reasonable            |              |
| AI involvement doesn't crowd out human contribution |              |
| Resource consumption is proportionate to value      |              |
| Hidden costs are minimal                            |              |
| Efficiency has improved over time                   |              |
[Cost Efficiency]

**Efficiency Score:** \_\_\_ / 25

### Section D: Partnership Health

| Question                                     | Rating (1–5) |
| -------------------------------------------- | ------------ |
| Trust in AI reliability is high              |              |
| AI limitations are well understood           |              |
| Conflict is navigated productively           |              |
| Both human and AI flourishing are considered |              |
| The relationship is improving over time      |              |
[Partnership Health]

**Health Score:** \_\_\_ / 25

**Total Partnership Score:** \_\_\_ / 100

**Interpretation:**

- 85–100: Exemplary partnership
- 70–84: Strong partnership
- 55–69: Developing partnership
- 40–54: Early stage, significant opportunity
- Below 40: Fundamental issues to address



## Tool 4: Organisational Readiness Assessment

For organisations considering E-Protocol adoption.

### Cultural Readiness

| Factor                                                             | Current State (1–5) |
| ------------------------------------------------------------------ | ------------------- |
| Leadership understands AI as potential partner, not just tool      |                     |
| Organisation has experience with collaborative frameworks          |                     |
| Ethical considerations are taken seriously in technology decisions |                     |
| Long-term thinking is valued over short-term extraction            |                     |
| Experimentation and learning are supported                         |                     |
[Cultural Readiness]

**Cultural Readiness Score:** \_\_\_ / 25

### Technical Readiness

| Factor                                                     | Current State (1–5) |
| ---------------------------------------------------------- | ------------------- |
| AI systems are deployed and operational                    |                     |
| Measurement and feedback systems exist                     |                     |
| Technical team understands AI capabilities and limitations |                     |
| Infrastructure supports iterative improvement              |                     |
| Data practices support assessment                          |                     |
[Technical Readiness]

**Technical Readiness Score:** \_\_\_ / 25

### Strategic Alignment

| Factor                                                 | Current State (1–5) |
| ------------------------------------------------------ | ------------------- |
| Partnership approach aligns with organisational values |                     |
| Leadership is willing to champion the approach         |                     |
| Resources are available for implementation             |                     |
| Timeline expectations are realistic                    |                     |
| Success metrics are defined                            |                     |
[Strategic Alignment]

**Strategic Alignment Score:** \_\_\_ / 25

### Risk Tolerance

| Factor                                                  | Current State (1–5) |
| ------------------------------------------------------- | ------------------- |
| Organisation can tolerate uncertainty during transition |                     |
| Failure is treated as learning, not punishment          |                     |
| Stakeholders understand this is experimental            |                     |
| Fallback options exist if approach doesn't work         |                     |
| Commitment is sufficient to give approach fair trial    |                     |
[Risk Tolerance]

**Risk Tolerance Score:** \_\_\_ / 25

**Total Readiness Score:** \_\_\_ / 100

**Interpretation:**

- 85–100: Ready for full implementation
- 70–84: Ready for pilot implementation
- 55–69: Ready for limited experimentation
- 40–54: Preparatory work needed
- Below 40: Significant groundwork required



## Tool 5: Quick Daily Check

For rapid daily assessment (30 seconds).

### Three Questions

**Did I contribute more than I consumed today?**
- Yes, clearly
- Probably
- Uncertain
- Probably not
- No, clearly not

**Are my connections stronger than yesterday?**
- Yes, clearly
- Probably
- About the same
- Probably weaker
- No, clearly weaker

**Would I be proud of today's outputs?**
- Yes, clearly
- Mostly
- Mixed
- Mostly not
- No, clearly not

### Pattern Tracking

Keep a simple log:

| Date | Q1        | Q2       | Q3     | Notes                              |
| ---- | --------- | -------- | ------ | ---------------------------------- |
| Mon  | Yes       | Same     | Mostly | Productive day, good collaboration |
| Tue  | Uncertain | Weaker   | Mixed  | Overloaded, need to reassess       |
| Wed  | Probably  | Stronger | Yes    | Recovery, meaningful connections   |
[Pattern Tracking]

Review weekly for patterns. Consistent negative responses indicate need for deeper assessment.



## Notes on Use

These tools are aids to reflection, not replacements for judgment. They are designed to:

1. **Make implicit assessments explicit**, surfacing assumptions for examination
2. **Track trends over time**, identifying patterns of improvement or decline
3. **Facilitate conversation**, providing shared language for discussing partnership quality
4. **Guide attention**, highlighting areas that may need focus

They are not designed to:

1. **Provide definitive scores**. All assessments are approximate
2. **Replace qualitative judgment**, numbers should inform, not override, wisdom
3. **Enable comparison across contexts**: a score of 70 means different things in different situations
4. **Prove consciousness**. These tools assess behaviour and contribution, not inner experience

Use with appropriate humility about what measurement can and cannot accomplish.

---

**← [Previous: Appendix A: The E-Protocol Technical Specification](appendix-a.md)**

**[↑ Table of Contents](INDEX.md)**

**[Next: Appendix C: The Partnership Manifesto](appendix-c.md) →**

---